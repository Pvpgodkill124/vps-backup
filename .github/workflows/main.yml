name: VPS 24/7#

on:
  schedule:
    - cron: '0 */6 * * *'  # Runs every 6 hours
  workflow_dispatch:

jobs:
  vps-session:
    runs-on: ubuntu-latest
    timeout-minutes: 350  # Just under 6 hours

    steps:
      - name: ‚¨áÔ∏è Checkout Repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GH_TOKEN }}

      - name: ‚öôÔ∏è Install Core System Prerequisites & Setup Backup Directory
        run: |
          # Define standard staging directory
          BACKUP_DIR="/opt/vps-backup"
          BACKUP_DATA_DIR="${BACKUP_DIR}/data"
          
          sudo hostnamectl set-hostname root
          sudo apt update
          # Install required packages including rclone for Google Drive
          sudo apt install -y tmate curl unzip sudo net-tools neofetch git mariadb-server zip rclone

          # Create the primary staging directory
          sudo mkdir -p "${BACKUP_DATA_DIR}"
          # Ensure the runner user owns the directory
          sudo chown -R $USER:$USER "${BACKUP_DIR}"

      - name: üîß Configure Rclone for Google Drive
        run: |
          echo "Configuring rclone with service account..."
          mkdir -p ~/.config/rclone
          
          # Create rclone config with service account
          cat > ~/.config/rclone/rclone.conf << EOF
          [gdrive]
          type = drive
          scope = drive
          service_account_credentials = ${{ secrets.GDRIVE_SA_JSON }}
          root_folder_id = ${{ secrets.GDRIVE_FOLDER_ID }}
          EOF
          
          echo "Rclone configured successfully!"
          rclone about gdrive: || echo "Google Drive connection test (might fail on first run)"
 
      - name: üì¶ Download Backup from Google Drive (Primary Source)
        run: |
          echo "::group::Downloading backup from Google Drive"
          BACKUP_FILE="backup.zip"
          
          # Try to download from Google Drive
          if rclone ls gdrive: | grep -q "${BACKUP_FILE}"; then
            echo "Backup found on Google Drive, downloading..."
            rclone copy gdrive:${BACKUP_FILE} ./ -P
            
            if [ -f ./${BACKUP_FILE} ]; then
              echo "‚úÖ Backup successfully downloaded from Google Drive!"
            else
              echo "‚ùå Download failed, trying Git branch backup..."
            fi
          else
            echo "‚ö†Ô∏è No backup found on Google Drive, trying Git branch..."
          fi
          echo "::endgroup::"
          
      - name: üì¶ Retrieve Backup from Git Branch (Fallback)
        run: |
          echo "::group::Retrieving backup from Git branch (if needed)"
          
          # Only try Git if Google Drive didn't work
          if [ ! -f ./backup.zip ]; then
            BACKUP_REPO_DIR=./backup_repo
            git clone --single-branch --branch backup https://oauth2:${{ secrets.GH_TOKEN }}@github.com/${{ github.repository }}.git ${BACKUP_REPO_DIR} 2>/dev/null || \
            git clone https://oauth2:${{ secrets.GH_TOKEN }}@github.com/${{ github.repository }}.git ${BACKUP_REPO_DIR}
            
            if [ -f ${BACKUP_REPO_DIR}/backup.zip ]; then
              cp ${BACKUP_REPO_DIR}/backup.zip ./backup.zip
              echo "‚úÖ Backup file retrieved from Git branch."
            else
              echo "‚ö†Ô∏è No backup file found anywhere, starting fresh."
            fi
            
            rm -rf ${BACKUP_REPO_DIR}
          else
            echo "‚úÖ Using Google Drive backup (skipping Git)."
          fi
          echo "::endgroup::"
          
      - name: üîÑ Restore Files and Tailscale State (FULL PERSISTENCE)
        run: |
          echo "Restoring previous session files..."
          BACKUP_DATA_DIR="/opt/vps-backup/data"
          
          if [ -f ./backup.zip ]; then
            # Unzip restores files to /opt/vps-backup/
            sudo unzip -o ./backup.zip -d /
            echo "‚úÖ Session files restored to /opt/vps-backup/."
            
            # --- START RESTORATION OF PERSISTENT FOLDERS ---
            
            # Restore /root home
            if [ -d ${BACKUP_DATA_DIR}/root_home ]; then
                echo "Restoring /root contents..."
                sudo cp -a ${BACKUP_DATA_DIR}/root_home/. /root/
                echo "‚úÖ /root restored"
            fi
            
            # Restore /incase folder
            if [ -d ${BACKUP_DATA_DIR}/incase ]; then
                echo "Restoring /incase contents..."
                sudo mkdir -p /incase
                sudo cp -a ${BACKUP_DATA_DIR}/incase/. /incase/
                echo "‚úÖ /incase restored"
            fi
            
            # Restore Pterodactyl Panel files
            if [ -d ${BACKUP_DATA_DIR}/pterodactyl_panel ]; then
                echo "Restoring Pterodactyl Panel..."
                sudo mkdir -p /var/www/pterodactyl
                sudo cp -a ${BACKUP_DATA_DIR}/pterodactyl_panel/. /var/www/pterodactyl/
                echo "‚úÖ Pterodactyl Panel restored"
            fi
            
            # Restore Pterodactyl Wings data
            if [ -d ${BACKUP_DATA_DIR}/pterodactyl_wings ]; then
                echo "Restoring Pterodactyl Wings..."
                sudo mkdir -p /var/lib/pterodactyl
                sudo cp -a ${BACKUP_DATA_DIR}/pterodactyl_wings/. /var/lib/pterodactyl/
                echo "‚úÖ Pterodactyl Wings restored"
            fi
            
            # Restore Nginx Configuration
            if [ -d ${BACKUP_DATA_DIR}/etc_nginx ]; then
                echo "Restoring Nginx configuration..."
                sudo cp -a ${BACKUP_DATA_DIR}/etc_nginx/. /etc/nginx/
                echo "‚úÖ Nginx config restored"
            fi
            
            # Restore Custom Systemd Service Files
            if [ -d ${BACKUP_DATA_DIR}/etc_systemd ]; then
                echo "Restoring systemd service files..."
                sudo cp -a ${BACKUP_DATA_DIR}/etc_systemd/. /etc/systemd/system/
                sudo systemctl daemon-reload
                echo "‚úÖ Systemd services restored"
            fi
            
            # --- END RESTORATION OF PERSISTENT FOLDERS ---

          else
            echo "‚ö†Ô∏è No backup found, starting fresh."
          fi
          
          # Restore Tailscale state
          if [ -f ${BACKUP_DATA_DIR}/tailscaled.state ]; then
            sudo mkdir -p /var/lib/tailscale
            sudo cp ${BACKUP_DATA_DIR}/tailscaled.state /var/lib/tailscale/tailscaled.state
            sudo chmod 600 /var/lib/tailscale/tailscaled.state
            echo "‚úÖ Tailscale state restored."
          fi
 
      # --- Networking and Service Installation Steps ---
      
      - name: üåê Install Networking Tools (Tailscale, Cloudflared, Playit)
        run: |
          # Install Tailscale
          curl -fsSL https://tailscale.com/install.sh | sh
          
          # Install Cloudflared
          curl -L https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64 -o cloudflared
          sudo install cloudflared /usr/local/bin/cloudflared
          
          # Install Playit.gg Agent
          echo "Setting up Playit.gg PPA..."
          curl -SsL https://playit-cloud.github.io/ppa/key.gpg | gpg --dearmor | sudo tee /etc/apt/trusted.gpg.d/playit.gpg >/dev/null
          echo "deb [signed-by=/etc/apt/trusted.gpg.d/playit.gpg] https://playit-cloud.github.io/ppa/data ./" | sudo tee /etc/apt/sources.list.d/playit-cloud.list
          sudo apt update
          sudo apt install -y playit
          
      - name: üîê Configure Root User and SSH Access
        run: |
          # Setup root user
          curl -s https://raw.githubusercontent.com/JishnuTheGamer/Vps/refs/heads/main/cd/root -o /tmp/root_setup.sh
          chmod +x /tmp/root_setup.sh
          sudo /tmp/root_setup.sh
          echo "root:root" | sudo chpasswd
          echo "root ALL=(ALL) NOPASSWD:ALL" | sudo tee /etc/sudoers.d/root
          sudo sed -i 's/PasswordAuthentication no/PasswordAuthentication yes/' /etc/ssh/sshd_config
          sudo sed -i 's/#PermitRootLogin prohibit-password/PermitRootLogin yes/' /etc/ssh/sshd_config
          sudo systemctl restart ssh || echo "SSH restart failed, continuing."

      - name: üöÄ Start Networking Services & Database
        run: |
          # Start Database
          sudo systemctl start mariadb || sudo systemctl start mysql || echo "Database service start failed."
          
          # Restore Pterodactyl Database
          if [ -f /opt/vps-backup/data/pterodactyl_db.sql ]; then
              echo "Re-importing Pterodactyl database..."
              sudo mysql -u root -p${{ secrets.DB_ROOT_PASSWORD }} panel < /opt/vps-backup/data/pterodactyl_db.sql || echo "Database restore failed."
          fi
          
          # Start Tailscale
          sudo tailscaled &
          
          # Wait for Tailscale daemon socket
          TS_SOCK="/var/run/tailscale/tailscaled.sock"
          echo "Waiting for Tailscale daemon socket..."
          for i in {1..20}; do
            if [ -S ${TS_SOCK} ]; then
              echo "‚úÖ Tailscale socket found!"
              break
            fi
            sleep 1
          done
          
          sudo tailscale up --authkey ${{ secrets.TAILSCALE_AUTHKEY }} --hostname=root --reset || echo "Tailscale already up"
          
          # Start Cloudflare Tunnel
          CLEAN_TOKEN=$(echo "${{ secrets.CF_TUNNEL_TOKEN }}" | tr -cd '[:print:]')
          sudo /usr/local/bin/cloudflared tunnel run --token "$CLEAN_TOKEN" &
          
          # Start Playit.gg
          playit --secret ${{ secrets.PLAYIT_SECRET_KEY }} &
   
          # Start Tailscale Funnel
          echo "Starting Tailscale Funnel on port 8080..."
          sudo tailscale funnel 8080 on &
          sleep 5

      - name: Start Tmate Server (Non-Blocking)
        run: tmate -S /tmp/tmate.sock new-session -d
 
      - name: üì£ VPS Connection Details (Ultimate Access)
        run: |
          echo "=========================================="
          echo "‚≠ê Access Details"
          echo "------------------------------------------"
          echo "üîê Tailscale MagicDNS Name: root"
          echo "üíª Tailscale IP (Internal VPN):"
          tailscale ip -4 || echo "Tailscale IP not found"
          echo "=========================================="
 
      - name: Sleep to Keep VPS Alive (6 Hours)
        run: sleep 21600
 
      # --- DUAL BACKUP: GOOGLE DRIVE + GIT BRANCH ---
      
      - name: üíæ Create Backup Archive (FULL CONFIGURATION PERSISTENCE)
        if: always()
        run: |
          BACKUP_DIR="/opt/vps-backup"
          BACKUP_DATA_DIR="${BACKUP_DIR}/data"
          
          echo "üîÑ Starting backup process..."
          
          # --- DUMP DATABASE ---
          echo "üìä Dumping Pterodactyl database..."
          sudo systemctl start mariadb || sudo systemctl start mysql || echo "Database service start failed."
          sleep 5
          sudo mysqldump -u root -p${{ secrets.DB_ROOT_PASSWORD }} panel > ${BACKUP_DATA_DIR}/pterodactyl_db.sql 2>/dev/null || \
          echo "‚ö†Ô∏è DB DUMP FAILED (might be empty)."
          
          # --- BACKUP CRITICAL FOLDERS ---
          
          # 1. /root/ contents (CRITICAL)
          echo "üìÅ Backing up /root directory..."
          sudo mkdir -p ${BACKUP_DATA_DIR}/root_home
          sudo rm -rf ${BACKUP_DATA_DIR}/root_home/*
          if [ -d /root ]; then
            sudo cp -a /root/. ${BACKUP_DATA_DIR}/root_home/ 2>/dev/null || echo "‚ö†Ô∏è /root backup partial"
            echo "‚úÖ /root backed up"
          fi

          # 2. /incase/ folder (CRITICAL)
          echo "üìÅ Backing up /incase directory..."
          sudo mkdir -p ${BACKUP_DATA_DIR}/incase
          sudo rm -rf ${BACKUP_DATA_DIR}/incase/*
          if [ -d /incase ]; then
            sudo cp -a /incase/. ${BACKUP_DATA_DIR}/incase/ 2>/dev/null || echo "‚ö†Ô∏è /incase backup partial"
            echo "‚úÖ /incase backed up"
          else
            echo "‚ö†Ô∏è /incase does not exist yet."
          fi
          
          # 3. Pterodactyl Panel files
          echo "üìÅ Backing up Pterodactyl Panel..."
          sudo mkdir -p ${BACKUP_DATA_DIR}/pterodactyl_panel
          if [ -d /var/www/pterodactyl ]; then
            sudo rm -rf ${BACKUP_DATA_DIR}/pterodactyl_panel/*
            sudo cp -a /var/www/pterodactyl/. ${BACKUP_DATA_DIR}/pterodactyl_panel/ 2>/dev/null
            echo "‚úÖ Pterodactyl Panel backed up"
          fi
          
          # 4. Pterodactyl Wings/Server data
          echo "üìÅ Backing up Pterodactyl Wings..."
          sudo mkdir -p ${BACKUP_DATA_DIR}/pterodactyl_wings
          if [ -d /var/lib/pterodactyl ]; then
            sudo rm -rf ${BACKUP_DATA_DIR}/pterodactyl_wings/*
            sudo cp -a /var/lib/pterodactyl/. ${BACKUP_DATA_DIR}/pterodactyl_wings/ 2>/dev/null
            echo "‚úÖ Pterodactyl Wings backed up"
          fi
          
          # 5. Tailscale state
          echo "üîê Backing up Tailscale state..."
          if [ -f /var/lib/tailscale/tailscaled.state ]; then
            sudo cp /var/lib/tailscale/tailscaled.state ${BACKUP_DATA_DIR}/ 2>/dev/null
            echo "‚úÖ Tailscale state backed up"
          fi

          # 6. Nginx/Systemd configs
          echo "‚öôÔ∏è Backing up configs..."
          sudo mkdir -p ${BACKUP_DATA_DIR}/etc_nginx ${BACKUP_DATA_DIR}/etc_systemd
          if [ -d /etc/nginx ]; then
            sudo rm -rf ${BACKUP_DATA_DIR}/etc_nginx/*
            sudo cp -a /etc/nginx/. ${BACKUP_DATA_DIR}/etc_nginx/ 2>/dev/null
          fi
          if [ -d /etc/systemd/system ]; then
            sudo rm -rf ${BACKUP_DATA_DIR}/etc_systemd/*
            sudo cp -a /etc/systemd/system/. ${BACKUP_DATA_DIR}/etc_systemd/ 2>/dev/null
          fi

          # --- CLEANUP ---
          echo "üßπ Cleaning up temporary files..."
          sudo rm -rf ${BACKUP_DATA_DIR}/root_home/.cache 2>/dev/null
          sudo rm -rf ${BACKUP_DATA_DIR}/root_home/.tmate.sock 2>/dev/null
          sudo rm -rf ${BACKUP_DATA_DIR}/root_home/.bash_history 2>/dev/null
          
          # Set ownership
          sudo chown -R $USER:$USER ${BACKUP_DIR}
          
          # --- CREATE ZIP ARCHIVE ---
          echo "üì¶ Creating backup.zip..."
          cd $GITHUB_WORKSPACE
          rm -f backup.zip
          zip -r backup.zip ${BACKUP_DIR} -q
          
          if [ -f backup.zip ]; then
            BACKUP_SIZE=$(du -h backup.zip | cut -f1)
            echo "‚úÖ Backup created successfully! Size: ${BACKUP_SIZE}"
          else
            echo "‚ùå BACKUP CREATION FAILED!"
            exit 1
          fi

      - name: ‚òÅÔ∏è Upload Backup to Google Drive (Primary Storage)
        if: always()
        run: |
          echo "üöÄ Uploading to Google Drive..."
          
          if [ -f backup.zip ]; then
            # Delete old backup first
            rclone delete gdrive:backup.zip 2>/dev/null || echo "No old backup to delete"
            
            # Upload new backup with progress
            rclone copy backup.zip gdrive: -P --transfers 1
            
            # Verify upload
            if rclone ls gdrive: | grep -q "backup.zip"; then
              echo "‚úÖ Backup successfully uploaded to Google Drive!"
              
              # Show backup info
              GDRIVE_SIZE=$(rclone ls gdrive:backup.zip | awk '{print $1}')
              echo "üìä Google Drive backup size: $(numfmt --to=iec-i --suffix=B $GDRIVE_SIZE)"
            else
              echo "‚ùå Google Drive upload verification FAILED!"
            fi
          else
            echo "‚ùå backup.zip not found, skipping upload"
          fi
 
      - name: üì§ Upload to Git Branch (Secondary Backup)
        if: always()
        run: |
          echo "üì§ Uploading to Git branch as fallback..."
          
          if [ -f backup.zip ]; then
            # Get current backup size
            LOCAL_SIZE=$(stat -f%z backup.zip 2>/dev/null || stat -c%s backup.zip)
            echo "üìä Local backup size: $(numfmt --to=iec-i --suffix=B $LOCAL_SIZE)"
            
            # Check if size is reasonable for Git (under 100MB)
            if [ $LOCAL_SIZE -lt 104857600 ]; then
              echo "‚úÖ Size OK for Git, proceeding..."
            else
              echo "‚ö†Ô∏è Backup too large for Git (>100MB), skipping Git upload"
              exit 0
            fi
          fi

      - name: üîÑ Create Pull Request with Backup (Git Fallback)
        id: cpr
        uses: peter-evans/create-pull-request@v6
        if: always()
        with:
          token: ${{ secrets.GH_TOKEN }} 
          commit-message: 'ü§ñ Automated Backup: Workflow ${{ github.run_id }}'
          title: 'Auto-Merge Backup: Workflow ${{ github.run_id }}'
          branch: backup-auto-merge-${{ github.run_id }} 
          base: backup 
          body: |
            Automated workflow backup (Git fallback).
            Primary backup stored in Google Drive.
            This PR will be merged automatically.
          add-paths: backup.zip 

      - name: ‚úÖ Auto-Merge the Pull Request (Git Fallback)
        if: steps.cpr.outputs.pull-request-number != ''
        run: |
          PR_NUMBER=${{ steps.cpr.outputs.pull-request-number }}
          echo "Merging PR #${PR_NUMBER}..."
          gh pr merge "$PR_NUMBER" --squash --delete-branch --admin
          echo "‚úÖ Git backup completed!"
        env:
          GITHUB_TOKEN: ${{ secrets.GH_TOKEN }}
